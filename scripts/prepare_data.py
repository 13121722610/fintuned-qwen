import json
import os
from datasets import Dataset
from datetime import datetime

def prepare_medical_dataset_correct():
    """æ­£ç¡®çš„åŒ»ç–—æ•°æ®é›†é¢„å¤„ç†"""
    
    # 1. æ–‡ä»¶è·¯å¾„
    input_file = "/amax/home/yhji/LM-Course//data/data-10k.json"  # ä¿®æ”¹ä¸ºæ‚¨çš„æ–‡ä»¶è·¯å¾„
    output_dir = "/amax/home/yhji/LM-Course/processed_data"
    
    print(f"ğŸ“‚ è¯»å–æ•°æ®: {input_file}")
    
    # 2. âœ… ä¿®æ”¹ï¼šè¯»å–JSONæ•°ç»„æ ¼å¼ï¼ˆæ‚¨çš„æ ¼å¼ï¼‰
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)  # ç›´æ¥åŠ è½½JSONæ•°ç»„
    
    print(f"ğŸ“Š åŸå§‹æ•°æ®æ¡æ•°: {len(data)}")
    
    # 3. è½¬æ¢æ ¼å¼ï¼ˆä¿æŒä¸å˜ï¼‰
    processed_data = []
    for i, item in enumerate(data):
        # æå–å„éƒ¨åˆ†
        system_prompt = item['instruction']  # ç³»ç»Ÿæç¤º
        user_question = item['input']        # ç”¨æˆ·é—®é¢˜
        assistant_answer = item['output']    # åŠ©æ‰‹å›ç­”
        
        # æ„å»ºæ­£ç¡®çš„å¯¹è¯æ ¼å¼
        processed_data.append({
            "id": i,
            "conversations": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_question},
                {"role": "assistant", "content": assistant_answer}
            ],
            "system_prompt": system_prompt,
            "user_question": user_question,
            "assistant_answer": assistant_answer
        })
    
    # 4. åˆ›å»ºæ•°æ®é›†ï¼ˆä¿æŒä¸å˜ï¼‰
    dataset = Dataset.from_list(processed_data)
    
    # 5. åˆ†å‰²æ•°æ®é›†ï¼ˆä¿æŒä¸å˜ï¼‰
    split_dataset = dataset.train_test_split(test_size=0.1, seed=42, shuffle=True)
    
    # 6. ä¿å­˜æ•°æ®é›†ï¼ˆä¿æŒä¸å˜ï¼‰
    os.makedirs(output_dir, exist_ok=True)
    split_dataset.save_to_disk(output_dir)
    
    # 7. ä¿å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¿æŒä¸å˜ï¼‰
    stats = {
        "total_samples": len(data),
        "train_samples": len(split_dataset['train']),
        "val_samples": len(split_dataset['test']),
        "split_ratio": "90%è®­ç»ƒ, 10%éªŒè¯",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "data_format": "system_prompt + user_question + assistant_answer",
        "format_example": {
            "system": "ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—é—®è¯Šä¸“å®¶ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºä¸“ä¸šçš„å›ç­”",
            "user": "å…·ä½“é—®é¢˜...",
            "assistant": "ä¸“ä¸šå›ç­”..."
        }
    }
    
    stats_file = os.path.join(output_dir, "dataset_stats.json")
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š è®­ç»ƒé›†: {len(split_dataset['train'])} æ¡")
    print(f"ğŸ“Š éªŒè¯é›†: {len(split_dataset['test'])} æ¡")
    print(f"ğŸ“Š ç»Ÿè®¡æ–‡ä»¶: {stats_file}")
    
    # 8. æ˜¾ç¤ºæ ·æœ¬ç¤ºä¾‹
    print(f"\nğŸ“ å‰3æ¡æ ·æœ¬ç¤ºä¾‹:")
    for i in range(min(3, len(processed_data))):
        print(f"\n--- æ ·æœ¬ {i+1} ---")
        print(f"ç³»ç»Ÿ: {processed_data[i]['conversations'][0]['content'][:50]}...")
        print(f"ç”¨æˆ·: {processed_data[i]['conversations'][1]['content'][:50]}...")
        print(f"åŠ©æ‰‹: {processed_data[i]['conversations'][2]['content'][:50]}...")
    
    return split_dataset

if __name__ == "__main__":
    prepare_medical_dataset_correct()